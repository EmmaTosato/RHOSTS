# Spiegazione Completa del Codice in `src`

Questa guida spiega tutti i moduli nella directory `src` del progetto RHOSTS.

---

## ðŸ“‹ Panoramica Generale

Il codice in `src` Ã¨ organizzato in due macro-aree:

1. **`src/preprocessing`** - Pre-processamento dati fMRI HCP
2. **`src/higher_order`** - Pipeline per l'analisi higher-order (configurata via JSON)

### Struttura Directory `src`

```
src/
â”œâ”€â”€ run_analysis.sh          # Script SLURM di lancio
â”œâ”€â”€ preprocessing/
â”‚   â”œâ”€â”€ preprocessing.sh
â”‚   â””â”€â”€ preprocessing_hcp.py
â””â”€â”€ higher_order/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ orchestration/
    â”‚   â””â”€â”€ main.py          # Entry point (legge config JSON)
    â”œâ”€â”€ nodal_strength/
    â”‚   â”œâ”€â”€ loaders_dv.py
    â”‚   â”œâ”€â”€ loaders_scaffold.py
    â”‚   â””â”€â”€ utils.py
    â””â”€â”€ visualization/
        â”œâ”€â”€ utils_neuromaps_brain.py
        â””â”€â”€ utils_nilearn_brain.py
```

---

## ðŸŽ¯ Configurazione via JSON

Il nuovo sistema usa un file `config.json` per tutti i parametri:

```json
{
  "mode": "dv",
  "scenario": "top_percent",
  "percent": 0.15,
  "metric": "coherence",
  "subjects_list_file": "/path/to/subjects.txt",
  "data_path_pattern": "/path/{subject}/{subject}_edge_projection.hd5",
  "indicators_path_pattern": "/path/{subject}/{subject}_indicators.txt",
  "num_rois": 116,
  "output": {
    "npy_path": "/path/output.npy",
    "img_path": "/path/output.png"
  }
}
```

### Parametri

| Parametro | Valori | Descrizione |
|-----------|--------|-------------|
| `mode` | `"dv"`, `"scaffold"` | Tipo di analisi |
| `scenario` | `"single_frame"`, `"all_frames"`, `"top_percent"` | Selezione frame |
| `percent` | 0.0-1.0 | Percentuale frame (per `top_percent`) |
| `metric` | `"coherence"`, `"complexity"` | Metrica per selezione |
| `subjects_list_file` | path | File txt con lista ID soggetti |
| `data_path_pattern` | pattern | Pattern con `{subject}` per file dati |
| `num_rois` | int | Numero ROI (default: 116) |

---

## ðŸ”¬ Parte 1: Preprocessing (`src/preprocessing`)

### `preprocessing_hcp.py`

**Obiettivo**: Estrarre time series ROI-averaged da dati fMRI 4D.

**Input**:
- fMRI data: `.nii.gz` 4D `(X, Y, Z, T)`
- Atlanti: corticale (100 ROI) + sottocorticale (16 ROI)

**Output**: File `.txt` con matrice `(T, 116)` normalizzata z-score.

---

## ðŸ§  Parte 2: Higher-Order Analysis (`src/higher_order`)

### Workflow Principale

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    config.json                           â”‚
â”‚  (mode, scenario, subjects_list, patterns, output)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    main.py                               â”‚
â”‚  1. Legge config JSON                                    â”‚
â”‚  2. Carica lista soggetti da subjects.txt                â”‚
â”‚  3. Per ogni soggetto:                                   â”‚
â”‚     - Seleziona frame (top 15% coherence, etc.)          â”‚
â”‚     - Carica nodal strength per ogni frame               â”‚
â”‚     - MEDIA SUI TIMEPOINTS â†’ vettore soggetto            â”‚
â”‚  4. MEDIA SUI SOGGETTI â†’ vettore finale                  â”‚
â”‚  5. Salva .npy e genera brain map .png                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Due ModalitÃ  di Analisi

**DV (Dynamic Violations)**:
- Input: file `.hd5` con edge projections da triangoli violanti
- Metrica default: `coherence` (valori ALTI = piÃ¹ sincronizzato)
- Colonna indicatori: 5 (hyper-coherence)

**Scaffold (Homological Scaffold)**:
- Input: directory con file `generators__*.pck`
- Metrica default: `complexity` (valori BASSI = piÃ¹ sincronizzato)
- Colonna indicatori: 1 (hyper-complexity)

### Scenari di Selezione Frame

| Scenario | Descrizione |
|----------|-------------|
| `single_frame` | Analizza un solo frame (richiede `frame` nel config) |
| `all_frames` | Analizza tutti i frame disponibili |
| `top_percent` | Seleziona top/bottom % secondo metrica |

---

## ðŸ“Š Logica di Aggregazione

Come richiesto dal paper (Santoro et al., Nature Physics 2023):

> "Results are averaged over all 100 HCP subjects and scans"

Il codice implementa esplicitamente:

```python
# Per ogni soggetto
for subj_id in subjects:
    # Media sui TIMEPOINTS selezionati
    for frame in selected_frames:
        nodal = load_nodal_strength(subj_id, frame)
        time_accum += nodal
    subject_avg = time_accum / n_frames
    subject_averages.append(subject_avg)

# Media sui SOGGETTI
group_mean = mean(subject_averages)  # Vettore finale (116,)
```

---

## ðŸš€ Come Lanciare

```bash
# 1. Crea/modifica config.json
# 2. Assicurati che subjects.txt contenga gli ID
# 3. Lancia:

sbatch src/run_analysis.sh config.json
```

**Output**:
- `.npy`: vettore nodal strength `(num_rois,)`
- `.png`: brain map (se ambiente supporta rendering)

---

## ðŸ”‘ Concetti Chiave

### Downward Projection
- **Dai triangoli agli archi**: peso arco = media pesi triangoli
- **Dagli archi ai nodi**: nodal strength = somma pesi archi incidenti

### Frame Selection
- La selezione Ã¨ basata su file `indicators.txt`
- Colonna 5 = hyper-coherence, Colonna 1 = hyper-complexity
- `coherence` prende valori ALTI, `complexity` prende valori BASSI
